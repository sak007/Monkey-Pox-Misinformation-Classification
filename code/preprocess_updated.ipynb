{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "d161b227",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d161b227",
        "outputId": "8df425ac-cff0-4e06-dce9-85601c14ee71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from io import StringIO\n",
        "\n",
        "import preprocessor as pp\n",
        "import emoji\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score,f1_score, recall_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9e618d68",
      "metadata": {
        "id": "9e618d68"
      },
      "outputs": [],
      "source": [
        "numeric_feat = np.array(['retweet_count','reply_count', 'like_count', 'quote_count', 'followers count', \n",
        "                    'following count', 'tweet count', 'listed_count'])\n",
        "\n",
        "cat_feat = np.array(['user is verified', 'user has url'])\n",
        "\n",
        "date_feat = np.array(['created_at', 'user created at'])\n",
        "\n",
        "text_feat = np.array(['text', 'user description'])\n",
        "\n",
        "\n",
        "class1 = 'binary_class'\n",
        "class2 = 'ternary_class'\n",
        "\n",
        "unused_feat = ['number', 'user created at', 'created_at', 'source', 'user location', class2]\n",
        "\n",
        "cls = class1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0ae30666",
      "metadata": {
        "id": "0ae30666"
      },
      "outputs": [],
      "source": [
        "def preprocess_cat(df, c):\n",
        "    # one hot encoding for categorical data\n",
        "    df = pd.get_dummies(df, columns = [c])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7a64e606",
      "metadata": {
        "id": "7a64e606"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def preprocess_date(df, c):\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "80d33825",
      "metadata": {
        "id": "80d33825"
      },
      "outputs": [],
      "source": [
        "def filter_text(df, c):\n",
        "    arr = []\n",
        "    for i in range (len(df)):\n",
        "        #Preprocess the tweets\n",
        "        oldtext=df[c][i]\n",
        "        #removes hashtags\n",
        "        newtext=' '.join(re.sub(\"(#[A-Za-z0-9]+)\",\" \",str(oldtext)).split())\n",
        "        #removes UserID\n",
        "        newtext=' '.join(re.sub(\"(@[A-Za-z0-9]+)\",\" \",str(newtext)).split())\n",
        "        #removes urls\n",
        "        newtext=' '.join(re.sub(\"(_URL_)\",\" \",str(newtext)).split())\n",
        "        #removes additional urls as well\n",
        "        newtext=' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\",\" \",str(newtext)).split())\n",
        "        #keeps only alphanumeric characters\n",
        "        newtext= re.sub('[^a-zA-Z0-9]',\" \",str(newtext))\n",
        "        #converts to lower case and splits\n",
        "        newtext=newtext.lower()\n",
        "        newtext=newtext.split()\n",
        "        #Performs Stemming    \n",
        "        ps=PorterStemmer()\n",
        "        newtext= [ps.stem(word) for word in newtext if word not in set(stopwords.words('english'))]\n",
        "        newtext=' '.join(newtext)\n",
        "        arr.append(newtext)\n",
        "    df[c] = np.array(arr)\n",
        "    return df\n",
        "                    \n",
        "def preprocess_text(df, c):\n",
        "    df = filter_text(df,c)\n",
        "    corpus=[]\n",
        "    for i in range(len(df)):\n",
        "        newtext=df[c][i]\n",
        "#         if(len(str((newtext)))!=0 and str(newtext)!='nan'):\n",
        "        corpus.append(newtext)\n",
        "\n",
        "    cv = CountVectorizer(max_features = 1000)\n",
        "    X2 = cv.fit_transform(corpus).toarray()\n",
        "    c_names = cv.get_feature_names_out()\n",
        "    c_names = [c + '_' + x for x in c_names]\n",
        "    df = df.drop(c, axis=1)\n",
        "#     for i in range(len(X2[0])):\n",
        "#         df[c + c_names[i]] = np.array(X2[:,i])\n",
        "    \n",
        "    df1 = pd.DataFrame(np.array(X2), columns=c_names)\n",
        "#     print(df1.columns)\n",
        "    \n",
        "    df = pd.concat([df,df1], axis=1)\n",
        "#     print(df.columns)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "614dda39",
      "metadata": {
        "id": "614dda39"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def preprocess_loc(df, c):\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "1b75375e",
      "metadata": {
        "id": "1b75375e"
      },
      "outputs": [],
      "source": [
        "def convert_to_numeric(df):\n",
        "    columns = df.columns\n",
        "    for c in columns:\n",
        "        if c in cat_feat:\n",
        "            df = preprocess_cat(df, c)\n",
        "        elif c in date_feat:\n",
        "            df = preprocess_date(df, c)\n",
        "        elif c in text_feat:\n",
        "            df = preprocess_text(df, c)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "835f1362",
      "metadata": {
        "id": "835f1362"
      },
      "outputs": [],
      "source": [
        "def normalize(df):\n",
        "    for feature in df.columns:\n",
        "        if feature != class1 and feature != class2:\n",
        "            feature_min = df[feature].min()\n",
        "            feature_max = df[feature].max()\n",
        "            df[feature] = (df[feature] - feature_min) / (feature_max - feature_min)    \n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "f3d2a6aa",
      "metadata": {
        "id": "f3d2a6aa"
      },
      "outputs": [],
      "source": [
        "def preprocess(df):\n",
        "    df = convert_to_numeric(df)\n",
        "    \n",
        "    df = normalize(df)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "072159aa",
      "metadata": {
        "id": "072159aa"
      },
      "outputs": [],
      "source": [
        "ds_train = pd.read_csv('monkeypox.csv')\n",
        "ds_test = pd.read_csv('monkeypox-followup.csv')\n",
        "\n",
        "ds_train = ds_train.drop(unused_feat, axis=1)\n",
        "ds_test = ds_test.drop(unused_feat, axis=1)\n",
        "ds_test = ds_test.drop('beto_flag', axis=1)\n",
        "ds_train = preprocess(ds_train)\n",
        "ds_test = preprocess(ds_test)\n",
        "\n",
        "cols_to_remove = np.setdiff1d(ds_test.columns, ds_train.columns)\n",
        "\n",
        "cols_to_add = np.setdiff1d(ds_train.columns, ds_test.columns)\n",
        "\n",
        "ds_test = ds_test.drop(cols_to_remove, axis=1)\n",
        "\n",
        "df1 = pd.DataFrame([[0 for i in range(len(cols_to_add))] for c in range(len(ds_test))], columns=cols_to_add)\n",
        "\n",
        "ds_test = pd.concat([ds_test, df1], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=ds_train.drop(cls,axis=1)\n",
        "x_test=ds_test.drop(cls,axis=1)\n",
        "y_train=ds_train[cls]\n",
        "y_test=ds_test[cls]"
      ],
      "metadata": {
        "id": "fkPgyNZChmXA"
      },
      "id": "fkPgyNZChmXA",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "rG81tKwCj5Go"
      },
      "id": "rG81tKwCj5Go",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "4e2b83cd",
      "metadata": {
        "id": "4e2b83cd"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "SVC2 = SVC(kernel = 'linear', random_state = 0)\n",
        "SVC2.fit(x_train, y_train)\n",
        "y_pred=SVC2.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Accuracy using Support Vector Clustering\",accuracy_score(y_test,y_pred)*100,\"%\")\n",
        "print(\"The Precision using Supprt Vector Clustering\",precision_score(y_test,y_pred))\n",
        "print(\"The Recall using Support Vector Clustering\",recall_score(y_test,y_pred))\n",
        "print(\"The F1 score using Supprt Vector Clustering\",f1_score(y_test,y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \\n\", cm)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI9qRP2jhN6L",
        "outputId": "732098dc-0856-4a32-dc30-4677ac2d0617"
      },
      "id": "yI9qRP2jhN6L",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy using Support Vector Clustering 88.77374784110536 %\n",
            "The Precision using Supprt Vector Clustering 0.7621951219512195\n",
            "The Recall using Support Vector Clustering 0.5787037037037037\n",
            "The F1 score using Supprt Vector Clustering 0.6578947368421053\n",
            "Confusion Matrix: \n",
            " [[903  39]\n",
            " [ 91 125]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifierrf = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', random_state = 0)\n",
        "classifierrf.fit(x_train, y_train)\n",
        "y_pred=classifierrf.predict(x_test)"
      ],
      "metadata": {
        "id": "4fqtFEoOmkbE"
      },
      "id": "4fqtFEoOmkbE",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Accuracy using Random Forest\",accuracy_score(y_test,y_pred)*100,\"%\")\n",
        "print(\"The Precision using Random Forest\",precision_score(y_test,y_pred))\n",
        "print(\"The Recall using Random Forest\",recall_score(y_test,y_pred))\n",
        "print(\"The F1 score using Random Forest\",f1_score(y_test,y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \\n\", cm)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1Ord4eqm8pr",
        "outputId": "82804b5c-7383-4e9e-cddb-ef91901f7ee6"
      },
      "id": "k1Ord4eqm8pr",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy using Random Forest 89.2055267702936 %\n",
            "The Precision using Random Forest 0.9504950495049505\n",
            "The Recall using Random Forest 0.4444444444444444\n",
            "The F1 score using Random Forest 0.6056782334384858\n",
            "Confusion Matrix: \n",
            " [[937   5]\n",
            " [120  96]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifierdt =DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifierdt.fit(x_train, y_train)\n",
        "y_pred=classifierdt.predict(x_test)"
      ],
      "metadata": {
        "id": "jjtXGSLCnIrA"
      },
      "id": "jjtXGSLCnIrA",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Accuracy using Decision Trees\",accuracy_score(y_test,y_pred)*100,\"%\")\n",
        "print(\"The Precision using Decision Trees\",precision_score(y_test,y_pred))\n",
        "print(\"The Recall using Decision Trees\",recall_score(y_test,y_pred))\n",
        "print(\"The F1 score using Decision Trees\",f1_score(y_test,y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmzHaxwHnO-e",
        "outputId": "29a9fa36-8a13-4adc-c1d7-9a8cce05bcc3"
      },
      "id": "wmzHaxwHnO-e",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy using Decision Trees 87.13298791018998 %\n",
            "The Precision using Decision Trees 0.675392670157068\n",
            "The Recall using Decision Trees 0.5972222222222222\n",
            "The F1 score using Decision Trees 0.6339066339066338\n",
            "Confusion Matrix: \n",
            " [[880  62]\n",
            " [ 87 129]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifierknn =KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski')\n",
        "classifierknn.fit(x_train, y_train)\n",
        "y_pred=classifierknn.predict(x_test)"
      ],
      "metadata": {
        "id": "ZTgNhKRhnkSw"
      },
      "id": "ZTgNhKRhnkSw",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Accuracy using Decision Trees\",accuracy_score(y_test,y_pred)*100,\"%\")\n",
        "print(\"The Precision using Decision Trees\",precision_score(y_test,y_pred))\n",
        "print(\"The Recall using Decision Trees\",recall_score(y_test,y_pred))\n",
        "print(\"The F1 score using Decision Trees\",f1_score(y_test,y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI7G42GknyJJ",
        "outputId": "8e56f8ab-ef09-46d0-c9ab-48d2618aeefe"
      },
      "id": "rI7G42GknyJJ",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy using Decision Trees 84.6286701208981 %\n",
            "The Precision using Decision Trees 1.0\n",
            "The Recall using Decision Trees 0.17592592592592593\n",
            "The F1 score using Decision Trees 0.2992125984251968\n",
            "Confusion Matrix: \n",
            " [[942   0]\n",
            " [178  38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifierGB = GaussianNB()\n",
        "classifierGB.fit(x_train, y_train)\n",
        "y_pred = classifierGB.predict(x_test)"
      ],
      "metadata": {
        "id": "fNwCCLBjnyh6"
      },
      "id": "fNwCCLBjnyh6",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Accuracy using Naive Bayes\",accuracy_score(y_test,y_pred)*100,\"%\")\n",
        "print(\"The Precision using Naive Bayes\",precision_score(y_test,y_pred))\n",
        "print(\"The Recall using Naive Bayes\",recall_score(y_test,y_pred))\n",
        "print(\"The F1 score using Naive Bayes\",f1_score(y_test,y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6V6-ITRoUQb",
        "outputId": "ba54714c-da82-4895-d416-021ad62093f0"
      },
      "id": "_6V6-ITRoUQb",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy using Naive Bayes 58.89464594127807 %\n",
            "The Precision using Naive Bayes 0.28114478114478114\n",
            "The Recall using Naive Bayes 0.7731481481481481\n",
            "The F1 score using Naive Bayes 0.41234567901234565\n",
            "Confusion Matrix: \n",
            " [[515 427]\n",
            " [ 49 167]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xxl53_2xoiEq"
      },
      "id": "Xxl53_2xoiEq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}