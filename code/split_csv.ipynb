{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "52406452",
      "metadata": {
        "id": "52406452"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "tweet_field = 'text'\n",
        "bio_field = 'user description'\n",
        "class1 = 'binary_class'\n",
        "class2 = 'ternary_class'\n",
        "cls = 'class'\n",
        "unused_feat = ['number', 'user location', 'source', class2]\n",
        "\n",
        "df = pd.read_csv('monkeypox.csv')\n",
        "\n",
        "df = df.drop(unused_feat, axis=1)\n",
        "df[cls] = df[class1]\n",
        "\n",
        "df = df.drop([class1], axis=1)\n",
        "\n",
        "df_bio = pd.DataFrame([df[bio_field], df[cls]]).transpose()\n",
        "df_tweet = pd.DataFrame([df[tweet_field], df[cls]]).transpose()\n",
        "df_hashtag = pd.DataFrame([df[tweet_field], df[cls]]).transpose()\n",
        "df_others = df.drop([bio_field, tweet_field], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "75238978",
      "metadata": {
        "id": "75238978"
      },
      "outputs": [],
      "source": [
        "# Filter text from df_hashtag\n",
        "df_hashtag = pd.DataFrame([df[tweet_field], df[cls]]).transpose()\n",
        "\n",
        "# Code to extract Hashtags from Tweets.\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "hashtags = []\n",
        "hashtag_col = []\n",
        "\n",
        "for i in range (0, len (df_hashtag)):\n",
        "      #print(i)\n",
        "      hashtags_set=[]\n",
        "      h_row=[]\n",
        "      s=df_hashtag['text'][i]\n",
        "\n",
        "      # removing URLs and usernames from the tweet text.\n",
        "      remove_URL = re.sub(r\"http\\S+\", \"\", s)\n",
        "      remove_username= re.sub('@[^\\s]+',' ', remove_URL)\n",
        "      stripped_q=remove_username.strip()\n",
        "      stripped_q.replace(\" \",\"\")\n",
        "      result=\" \".join(stripped_q.split())\n",
        "      for vocab in result.split():\n",
        "          # searching for hashtags.\n",
        "          stripped_q=re.search('#[a-zA-Z0-9_#]+$', vocab)\n",
        "          if stripped_q is not None:\n",
        "              h_row.append(stripped_q.group(0))\n",
        "              words=set(h_row)\n",
        "              h_row=list(words)\n",
        "             \n",
        "              if h_row is not None:\n",
        "                  for hashtag in h_row:\n",
        "                      tag=hashtag.split('#')\n",
        "                      tag.remove('')\n",
        "                      if tag is not None:\n",
        "                          hashtags_set.extend(tag)\n",
        "                        \n",
        "                      hashtags_set=list(set(hashtags_set))\n",
        "                      \n",
        "      for hash in hashtags_set:\n",
        "        hashtags.append (hash)\n",
        "      \n",
        "      hashtag_col.append (hashtags_set)\n",
        "# print (\"hashtags:\", hashtags)\n",
        "\n",
        "# make comma seperated hashtags from the array of hashtags\n",
        "hash = []\n",
        "for row in hashtag_col:\n",
        "  hash_with_comma = ''\n",
        "  i = 0\n",
        "  for single_hash in row:\n",
        "    if i > 0:\n",
        "      hash_with_comma = hash_with_comma + \", \" + single_hash\n",
        "    else:\n",
        "      hash_with_comma = hash_with_comma + single_hash\n",
        "    i = i + 1\n",
        "  hash.append (hash_with_comma)\n",
        "\n",
        "# build dataframe for hashtags\n",
        "hash_df = pd.DataFrame ()\n",
        "hash_df['hashtag'] = list(hash)\n",
        "hash_df['class'] = df_hashtag['class']\n",
        "\n",
        "df_hashtag = hash_df.copy()\n",
        "\n",
        "# print (df_hashtag.head (10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "705b841b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "705b841b",
        "outputId": "87c672d4-bab5-47fd-a69f-0b930c13d2db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user description', 'class'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "df_bio.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "229727a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "229727a6",
        "outputId": "776b313c-c4bd-48e1-b61e-4e8c4d7f0b83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'class'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df_tweet.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "9ad2ff0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ad2ff0f",
        "outputId": "6d05e817-bfa3-43fb-e2ae-5db5b4f1419b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['hashtag', 'class'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "df_hashtag.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "b3685ce7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3685ce7",
        "outputId": "18ef78b5-bb3d-4d8d-b8dc-4b1d5cbe8c5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['created_at', 'user is verified', 'user has url', 'user created at',\n",
              "       'retweet_count', 'reply_count', 'like_count', 'quote_count',\n",
              "       'followers count', 'following count', 'tweet count', 'listed_count',\n",
              "       'class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "df_others.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "d57c6d82",
      "metadata": {
        "id": "d57c6d82"
      },
      "outputs": [],
      "source": [
        "os.makedirs('filtered_dataset', exist_ok=True)\n",
        "df_bio.to_csv('filtered_dataset/bio.csv') \n",
        "df_tweet.to_csv('filtered_dataset/tweet.csv') \n",
        "df_hashtag.to_csv('filtered_dataset/hashtag.csv') \n",
        "df_others.to_csv('filtered_dataset/others.csv') "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}